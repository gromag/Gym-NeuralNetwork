{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring neural networks\n",
    "\n",
    "## Problem 4\n",
    "\n",
    "Given the MNIST dataset classify those images that represent numbers greater or equal to 5. In other words, what is the probability that the number is >=5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('Gym 5/train.csv')\n",
    "df_test = pd.read_csv('Gym 5/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 784)\n"
     ]
    }
   ],
   "source": [
    "df_features = df_train.iloc[:, 1:785]\n",
    "df_label = df_train.iloc[:, 0]\n",
    "\n",
    "X_testdf = df_test.iloc[:, 0:784]\n",
    "\n",
    "print(X_testdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(df_features, df_label, \n",
    "                                                test_size = 0.2,\n",
    "  \n",
    "                                                random_state = 1212)\n",
    "eighty_percent = int(df_features.shape[0] * 0.8)\n",
    "twenty_percent = int(df_features.shape[0] * 0.2)\n",
    "test_size = X_testdf.shape[0]\n",
    "\n",
    "X_train = X_train.values.reshape(eighty_percent, 784) #(33600, 784)\n",
    "X_cv = X_cv.values.reshape(twenty_percent, 784) #(8400, 784)\n",
    "\n",
    "X_test = X_testdf.values.reshape(test_size, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32'); X_cv= X_cv.astype('float32'); X_test = X_test.astype('float32')\n",
    "X_train /= 255; X_cv /= 255; X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Parameters\n",
    "n_input = 784 # number of features\n",
    "n_hidden_1 = 300\n",
    "n_hidden_2 = 100\n",
    "n_hidden_3 = 100\n",
    "n_hidden_4 = 200\n",
    "num_digits = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=300, bias=True)\n",
      "  (fc2): Linear(in_features=300, out_features=100, bias=True)\n",
      "  (fc3): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fc4): Linear(in_features=100, out_features=200, bias=True)\n",
      "  (fc5): Linear(in_features=200, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "#         self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "#         self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(n_input, n_hidden_1) \n",
    "        self.fc2 = nn.Linear(n_hidden_1, n_hidden_2)\n",
    "        self.fc3 = nn.Linear(n_hidden_2, n_hidden_3)\n",
    "        self.fc4 = nn.Linear(n_hidden_3, n_hidden_4)\n",
    "        self.fc5 = nn.Linear(n_hidden_4, num_digits)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "#         x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "#         x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "#         x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        \n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(df_train.iloc[0:100, 1:].values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_train_test_data(ds, split_percent=0.8):\n",
    "    \n",
    "    split = round(ds.shape[0] * split_percent)\n",
    "       \n",
    "    x_train = torch.tensor(ds.iloc[0:split, 1:].values, dtype=torch.float32)\n",
    "    y_train = torch.tensor(ds.iloc[0:split, 0].values, dtype=torch.long)\n",
    "      \n",
    "    train_data = data.TensorDataset(x_train, y_train)\n",
    "\n",
    "    x_test = torch.tensor(ds.iloc[split:, 1:].values, dtype=torch.float32)\n",
    "    y_test = torch.tensor(ds.iloc[split:, 0].values, dtype=torch.long)\n",
    "    \n",
    "    test_data = data.TensorDataset(x_test, y_test)\n",
    "       \n",
    "    return (x_train, y_train, x_test, y_test, train_data, test_data)\n",
    "\n",
    "\n",
    "x_train, y_train, x_test, y_test, train_data, test_data = torch_train_test_data(df_train, 0.8)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=4,\n",
    "                                         shuffle=False, num_workers=0) \n",
    "    \n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=4,\n",
    "                                         shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  4200] loss: 0.539\n",
      "[1,  8400] loss: 0.165\n",
      "[2,  4200] loss: 0.237\n",
      "[2,  8400] loss: 0.112\n",
      "[3,  4200] loss: 0.191\n",
      "[3,  8400] loss: 0.097\n",
      "[4,  4200] loss: 0.163\n",
      "[4,  8400] loss: 0.087\n",
      "[5,  4200] loss: 0.141\n",
      "[5,  8400] loss: 0.075\n",
      "[6,  4200] loss: 0.142\n",
      "[6,  8400] loss: 0.066\n",
      "[7,  4200] loss: 0.143\n",
      "[7,  8400] loss: 0.062\n",
      "[8,  4200] loss: 0.106\n",
      "[8,  8400] loss: 0.051\n",
      "[9,  4200] loss: 0.095\n",
      "[9,  8400] loss: 0.046\n",
      "[10,  4200] loss: 0.097\n",
      "[10,  8400] loss: 0.059\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        \n",
    "#         print(inputs)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        print_every = round(df_train.shape[0] * 0.1)\n",
    "        if i % print_every == print_every - 1:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / i))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 8400 test images: 94 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        input_data, labels = data\n",
    "        # Note input data is batched, so output is batched\n",
    "        outputs = net(input_data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the %d test images: %d %%' % (x_test.size()[0],\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def compare_prediction(i):\n",
    "    output = list(net(x_test[i]).detach().numpy())\n",
    "\n",
    "    prediction = output.index(max(output))\n",
    "\n",
    "    array = np.array((x_test[i].reshape(28,28))).astype(np.uint8)\n",
    "\n",
    "    img = Image.fromarray(array)\n",
    "    \n",
    "    return (img, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted 0 \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABF0lEQVR4nMWPP0sDQRDFX8TmOA7URlMmGItAOCwVQUFO/PMVAlZa2FikEPwG6pWKgpXXxnQasbNVCwXhUgmCkhTWJwpvWAvXvb2ctjrFMjO/mTdvgf8Md6y2BvdAROTc6WMToTCaaUuPpLS8LLyjMChWgkqw+SY8ysJjJnt6vvrA++G+za7Jd8kr12ILIo+pt1uRUQADul5U6tDAJFZKpbBcB05zv9PQG0H8ZJpOCVi1ZIGLdGN+GmgCGPwqGwVbbraA98TA8SllbyqF5quRXS8Bcc6PddOKKtD5DW4sAe20XE5E9nU+eSbqo2EPhySj0Pf96OSFlMuMUvmGFFI/28XsHa/1DZ+3ajkXzso1Se7MDf3k/+/iExRNdXdHziTvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x1A50A9B8D0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted 7 \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA6UlEQVR4nN3Qvy5EQRiG8Sf+NasUFbIohA5RaE6hU6DZuyAKEiFRKEQ0EoV7UOmdSuUSVLsnkhNRbMFKVk7zTChEGDlzA75mkvnlnbzfwD+cZju8LqfwWH3Z3sngqHc1F9t6pWp4K8tKLwAY+sal4a+z0QBYiIK7fe2c552gaj4WYanuwezapeoW8bNAAUUxD1T9uM9p9/1+EuBOvf27ycwmABuVPkwktg3qfsL4CCGsJOwk6OFgvWW9oD9fNxBhaxTOHuuDq8+G65F6m3rScJBok6ndRgJv1MWENdtqdPOr7fg05IlgzXwCgHpnpN+Q/8YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x1A50A9BCF8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted 7 \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAp0lEQVR4nGNgGJ7AynPx4o///h1xQ5cQCdx4/+ffd8eOnfr7LwdNzu7ZpghDFRUpBgbfv2fE0CRdf5hAGMyn/4Zi2GcCU/X3Dm5H3YIZgQUY/5qG4DChSQb+XYpTUuFryVGcpq56rILbOf9v8eKW/FeMzEO105rhDE59/O/+CeGUFP57ihWn5PJ/MTjlRJ/9Zccpqfp3PaoAqmvf4NTIoPpND7ckBgAAY+o0Oo4B4HUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x1A50A9BD68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted 2 \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABBUlEQVR4nGNgGGSAEcFk7ii65JnB+p9hw4U/6MoEO/78+fPnz98/f/70oEmxmN39A5c8ABOEGllVB2Fc+s+sg25m8p8/f/68nu7hwcIgiaFTkYGBYX3DVQYGBgYlDEe3/PlTzMfAwMDAwPXiz584VEnhzEAeCKv0z59LXNg8zcDAwLDjz594XHJr//75syQGiwRX/ua/f////fv3bz0zmpRg/mNYIPz5szQKRU4DKYT+/PlzYy473J8MGlvlIYznd5amM/ApCekzwfWp3YNo+HNImYGBgUHUQxfJ0BaoXBuKS1iQOU9mdf/FJfnE7xKqB5Akn/lexuJ5BgYGt/4/0ZzYpagPAB1gf0/pk+E9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x1A50A9B128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted 2 \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA3UlEQVR4nGNgoD9ghNJseUH7GPbdeYRVkeqPLz/+/Pt4bLEuE6ZOBoUHCqr6mgKBDM0T3uOwhVlozY86PK7Y+McVtyTPtWl4tB77LQRlMWGR/fUPpyS/6N4POE21/xeK28obrzVhTBaY8frmSvceHvz/e75CxXV09Y3//v379+/fl5P/ngjDBaHBZ76Le9t+hkAbBgaGv6dOMDAwMMhdq4dJvhVsaOKOLZf/u/Llfy9Rhp8r3my6Bjfg/7/qKXf//Xtdgs2Jx/79+/fvyVIurO43mPhwkY4obv8NBQAAz6NRp+UXlZYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x1A50A9B8D0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted 6 \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAzElEQVR4nGNgoAtQWHWYH5cc57q/+5hwSTb9veSMSy70+xdXXHJSd/8V4nTNhn+XRHHJ2X347o5T47a/03HKyb39p4RTcvLfUzjlGJ79DUUTQQSHFOf36wwMDC472wQxNbr9+6rDwND779+/o5g6Gf5zSPKu4Zac9V+VF0Mn76u/rh7+DAxuf1/BJFngkp//MDDsYGBgUGL48xnT0jX/4hgYGKT+f8QWLwFfLgsyMOT968Yix8Bw/O/xkrkvtrBglVRIv/P3cjpWqUECAAJcQqof/a2DAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x1A50A9BCF8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted 5 \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA7UlEQVR4nGNgGK7Ap4IDwjAsE0OX0/9ygw/Cqvo3jYGBBVmO1/TXWVN7BgYGzgRBBgVUfcYn/z389+/fv3///v+7V8KHIid87d9DjX///v378H6ioyADA4qxWzT+tt2KYmBgWPcLw6Eqn//PxO4FLh4G51//fvhglYzawMLQv+PfjSRsklP/cTEwKCz492+XPqbk7n9cDAwMLHn//j1jwZC0+fdQhYGBgcXm1L95CFEmCPWFQbZZnYHhz7MPDOIYOiUu/fv36Xjz0w//zllgcVLmv3///v37u9sDSYwRxmCTMzNiYFhxBptfBg0AAL4JVOXOEIZnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x1A50A9B128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted 7 \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAr0lEQVR4nGNgGDaAEcawDJBh0NdiYPzPuCocJsYCpfdbszAwMPw4ycBgK8+ALvl4wymGNb/+vmTQOceAIRkHE1BlQUgyoTtCneEHbklDhvU4JZlkMX0EB7H/LnPh1MnI8OIbTkk/hk04TbX6+M8cp2TOv/1IZqEZa8+w7h8ujaKvf8vgNLXs3yKcclyXfznglKz6Nx+Fj+IgU4bTODUy3H/Ih8JnQeY8PPoJt050AACjaSkR7/qAKgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x1A50A9B8D0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted 8 \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABH0lEQVR4nM3Pv0uCcRDH8bcgQdAzRZRBEQ0OljY8UENTELUEBU3RkFN/QkZjQ9gQFC6FtDgF4hpJS/RjyqHpKSIiMEJKwSyxkDsbJIrv1zn6jPe64+7gP6RzauesUepraZM5KWRKcuvY5GyVdT3AqlSClvV6ko23QbiaC1h4rN44wJKmLTvQUwdguZq3DgpfP04AY/tlb9Ya7BHtZjB2IWIvxH1RVVV9+i74f2wo2kGj7vkCfufNGGuff6ik5iIhSNSjph2pTAPuils7Nyy4p9kZoP9S9XXDwDUphgCcO9GMYYuflVEAkiJJv4FxSTWfuZfYrx+bbR++AoAbHzjcxMy2nIzQm6hpvssygs8iVzfyno7YBgtF0eLucCv643wBLt9vF2CIzeAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x1A50A9BCF8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted 5 \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABEElEQVR4nGNgGGSAEUIJJ0l8maMqeYiBwehcci1DYxOSEuGHf/78/YPADyHCLAwMDAwMXNIMt+54QURWM9za9gvZcJZNf7pZZByjZNLTZTCtXvX3NG53BX34I4Vbdv6faQyyoceOHj0aimlw6J9f0+ZDXPtqvTeqPxnCljP9Y/jiZ8TAUCjEybAt/Buqzr9/VukzMDAwMFhUffubi2Ks8PO/R1RhnJS/HwJRZNd/1Edw0v+swO12hpU3BBgYGJhwyKrw4JTkwhKIcOD/ZyMzgsdeur+RC87j/fd3DpJSnQ9//h5ptpRSs7RkD1p57nulMLJBgStWPPjz5/6rP3/O/PnzJwXDIp2NkLDdiC1OqQkAThxxGNBWyccAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x1A50A9B438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for i in range(0, 10):\n",
    "    (img, pred) = compare_prediction(i)\n",
    "    print('predicted %d ' % pred)\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "quadcop",
   "language": "python",
   "name": "quadcop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
